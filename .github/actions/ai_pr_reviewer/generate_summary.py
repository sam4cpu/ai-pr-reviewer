import os
import json
import re
from datetime import datetime

def extract_section(text, header):
    """Extract a markdown section by its header."""
    pattern = rf"##+ {header}[\s\S]*?(?=\n##|\Z)"
    match = re.search(pattern, text, re.IGNORECASE)
    return match.group(0).strip() if match else f"_{header} section missing_"

def count_bullets(section_text):
    """Count markdown bullets for quick scoring."""
    return len(re.findall(r"^- ", section_text, flags=re.MULTILINE))

def detect_high_risk_terms(text):
    """Detect security or stability red flags."""
    risk_terms = [
        "security", "vulnerability", "crash", "data loss",
        "leak", "injection", "auth", "password", "corruption"
    ]
    lowered = text.lower()
    return [term for term in risk_terms if term in lowered]

def compute_confidence_score(summary, issues, suggestions, risks):
    """Weighted heuristic for confidence and risk adjustment."""
    length_factor = len(summary) / 200
    balance = abs(count_bullets(issues) - count_bullets(suggestions))

    base_score = 100 - (balance * 5) - (10 if "missing" in summary.lower() else 0)
    if length_factor < 0.5:
        base_score -= 10

    # Penalize for risk presence
    if risks:
        base_score -= len(risks) * 5
        base_score = min(base_score, 80)

    return max(30, min(95, int(base_score)))

def main():
    review_path = "artifacts/ai_review.md"
    if not os.path.exists(review_path):
        print("[FATAL] No ai_review.md found â€” ensure artifacts are downloaded.")
        return

    print(f"[INFO] Reading AI review from {review_path}...")
    with open(review_path, "r", encoding="utf-8") as f:
        review_text = f.read()

    summary = extract_section(review_text, "Summary")
    issues = extract_section(review_text, "Potential Issues")
    suggestions = extract_section(review_text, "Suggestions")
    tests = extract_section(review_text, "Testing Recommendations")

    # --- Analytics ---
    bullet_issues = count_bullets(issues)
    bullet_suggestions = count_bullets(suggestions)
    risks = detect_high_risk_terms(review_text)
    score = compute_confidence_score(summary, issues, suggestions, risks)

    summary_data = {
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "summary": summary,
        "potential_issues": bullet_issues,
        "suggestions": bullet_suggestions,
        "confidence_score": score,
        "high_risk_terms": risks,
    }

    # --- Save summary ---
    with open("review_summary.json", "w", encoding="utf-8") as jf:
        json.dump(summary_data, jf, indent=2)
    print("[INFO] Saved structured summary to review_summary.json")

    md_content = f"""## AI Review Summary

**Confidence Score:** {score}/100  
**Detected Issues:** {bullet_issues}  
**Suggestions:** {bullet_suggestions}  
**High-Risk Keywords:** {', '.join(risks) if risks else 'None'}

### Summary
{summary}

### Potential Issues
{issues}

### Suggestions
{suggestions}

### Testing Recommendations
{tests}

---

_This summary was automatically generated by the AI PR Reviewer workflow._
"""
    with open("review_summary.md", "w", encoding="utf-8") as mf:
        mf.write(md_content)
    print("[SUCCESS] review_summary.md generated successfully.")

if __name__ == "__main__":
    main()

